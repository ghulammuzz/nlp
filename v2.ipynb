{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.sastra.org/bahasa-dan-budaya/kagunan/1399-kawruh-ambathik-nyerat-kajawen-1938-1671\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "paragraphs = soup.find_all(\"p\")\n",
    "for p in paragraphs:\n",
    "    content.append(p.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lingkup pencarian: teks dan catatan-kakinya. Teks pencarian: 2-24 karakter. Filter pencarian: huruf besar/kecil, diakritik serta pungtuasi diabaikan; karakter [?] dapat digunakan sebagai pengganti zero atau satu huruf sembarang; simbol wildcard [*] dapat digunakan sebagai pengganti zero atau sejumlah karakter termasuk spasi; mengakomodasi variasi ejaan, antara lain [dj : j, tj : c, j : y, oe : u, d : dh, t : th].',\n",
       " '--- 390 ---',\n",
       " 'Dumuginipun ing măngsa punika, ingkang nama taksih têtêp migunakakên sinjang, namung tiyang èstri, tuwin saprika-sapriki, ingkang nama sinjang sae, punika botên ewah, inggih punika sinjang bathik (sêratan tangan). Ingkang nama sinjang bathik punika manawi dipun tandhing saenipun tinimbang sinjang cap, kathah sangêt bedanipun, makatên ugi awèting panganggenipun, mila rêganipun inggih tikêlan.',\n",
       " 'Bakuning sinjang bathik ingkang nama sae, punika kêdah mrêtamèni, kados ta mori kêdah sae. Sêratanipun ingkang alus, nêtês, têgêsipun nêtês, canthing-canthing ingkang cêtha awijang, dumugi têrusanipun pisan, malam sae tuwin cêlêpanipun sêpuh. Soganipun mandhês.',\n",
       " 'Ingkang nama mori sae, punika sadaya kados sampun botên kêkilapan, awit ing pundi sabên wontên tiyang nyêrat (ambathik) inggih wontên mori sae. Nanging dadosing mori ingkang lajêng kenging dipun sêrat, punika taksih dipun upakara malih, inggih punika dipun loyori utawi dipun kêmplongi.',\n",
       " 'Alusing sêratan, punika kajawi saking alusing canthing, ugi saking caking tangan, malah caking tangan punika [pu...]',\n",
       " '--- 391 ---',\n",
       " '[...nika] ingkang nama baku piyambak. Sayêktosipun tiyang sagêd nyêrat sae punika saking pakulinan, awit botên kirang tiyang ingkang baut nyêrat, ingkang sêratanipun awon. Ingkang makatên punika jalaranipun saking sampun kêtlêtuh rêmên nyêrat rikatan, mila tiyang sinau nyêrat punika kêdah alon, mangke manawi sampun matuh sanadyan nyêrat rikat, inggih sae.',\n",
       " 'Caranipun tiyang nyêrat punika wontên warni tiga, polan, rujagan, tuwin garisan. Ingkang dipun wastani polan, punika wanguning sêratan mêndhêt saking mola sêratan sanès, sarana dipun tèmplèkakên ing mori ingkang dipun sêrat, tuwin sanadyan pamolanipun sampun dipun tèmplèkakên, tumrap ingkang sagêd taksih dipun ewahi sakêdhik, murih dados luwês. Rujagan punika panyêratipun botên mawi pola, namung apalan kemawon, utawi nganggit, mila limrahipun namung tumrap tiyang ingkang sampun sagêd sayêktos. Polan tuwin rujagan punika ingkang kathah bangsaning sêmèn-sêmenan, garisan punika panyêratipun manut ing garisan ingkang sampun dipun damêl wontên ing mori, sêratanipun bangsaning cêplok tuwin garis miring.',\n",
       " 'Urut-urutaning tiyang nyêrat punika: ngèngrèng, ngisèni, nêrusi tuwin nembok. Ngèngrèng punika damêl cêngkorongan, ngisèn-isèni punika ngisèni cêngkorongan wau, kados ta: cêcêk, sawut, nêrusi punika nyêrat sawalikipun, dene nembok punika nutup sêratan murih ing salajêngipun dados pêthak, bab nyêrat sadaya wau botên kenging kasupèn, lilinipun kêdah sae.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_content = []\n",
    "for item in content:\n",
    "    if not item.strip().startswith(\"---\") and not item.strip().endswith(\"---\"):\n",
    "        clean_content.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lingkup pencarian: teks dan catatan-kakinya. Teks pencarian: 2-24 karakter. Filter pencarian: huruf besar/kecil, diakritik serta pungtuasi diabaikan; karakter [?] dapat digunakan sebagai pengganti zero atau satu huruf sembarang; simbol wildcard [*] dapat digunakan sebagai pengganti zero atau sejumlah karakter termasuk spasi; mengakomodasi variasi ejaan, antara lain [dj : j, tj : c, j : y, oe : u, d : dh, t : th].',\n",
       " 'Dumuginipun ing măngsa punika, ingkang nama taksih têtêp migunakakên sinjang, namung tiyang èstri, tuwin saprika-sapriki, ingkang nama sinjang sae, punika botên ewah, inggih punika sinjang bathik (sêratan tangan). Ingkang nama sinjang bathik punika manawi dipun tandhing saenipun tinimbang sinjang cap, kathah sangêt bedanipun, makatên ugi awèting panganggenipun, mila rêganipun inggih tikêlan.',\n",
       " 'Bakuning sinjang bathik ingkang nama sae, punika kêdah mrêtamèni, kados ta mori kêdah sae. Sêratanipun ingkang alus, nêtês, têgêsipun nêtês, canthing-canthing ingkang cêtha awijang, dumugi têrusanipun pisan, malam sae tuwin cêlêpanipun sêpuh. Soganipun mandhês.',\n",
       " 'Ingkang nama mori sae, punika sadaya kados sampun botên kêkilapan, awit ing pundi sabên wontên tiyang nyêrat (ambathik) inggih wontên mori sae. Nanging dadosing mori ingkang lajêng kenging dipun sêrat, punika taksih dipun upakara malih, inggih punika dipun loyori utawi dipun kêmplongi.',\n",
       " 'Alusing sêratan, punika kajawi saking alusing canthing, ugi saking caking tangan, malah caking tangan punika [pu...]',\n",
       " '[...nika] ingkang nama baku piyambak. Sayêktosipun tiyang sagêd nyêrat sae punika saking pakulinan, awit botên kirang tiyang ingkang baut nyêrat, ingkang sêratanipun awon. Ingkang makatên punika jalaranipun saking sampun kêtlêtuh rêmên nyêrat rikatan, mila tiyang sinau nyêrat punika kêdah alon, mangke manawi sampun matuh sanadyan nyêrat rikat, inggih sae.',\n",
       " 'Caranipun tiyang nyêrat punika wontên warni tiga, polan, rujagan, tuwin garisan. Ingkang dipun wastani polan, punika wanguning sêratan mêndhêt saking mola sêratan sanès, sarana dipun tèmplèkakên ing mori ingkang dipun sêrat, tuwin sanadyan pamolanipun sampun dipun tèmplèkakên, tumrap ingkang sagêd taksih dipun ewahi sakêdhik, murih dados luwês. Rujagan punika panyêratipun botên mawi pola, namung apalan kemawon, utawi nganggit, mila limrahipun namung tumrap tiyang ingkang sampun sagêd sayêktos. Polan tuwin rujagan punika ingkang kathah bangsaning sêmèn-sêmenan, garisan punika panyêratipun manut ing garisan ingkang sampun dipun damêl wontên ing mori, sêratanipun bangsaning cêplok tuwin garis miring.',\n",
       " 'Urut-urutaning tiyang nyêrat punika: ngèngrèng, ngisèni, nêrusi tuwin nembok. Ngèngrèng punika damêl cêngkorongan, ngisèn-isèni punika ngisèni cêngkorongan wau, kados ta: cêcêk, sawut, nêrusi punika nyêrat sawalikipun, dene nembok punika nutup sêratan murih ing salajêngipun dados pêthak, bab nyêrat sadaya wau botên kenging kasupèn, lilinipun kêdah sae.',\n",
       " 'Sêpuhing cêlêpan punika gumantung wontên saening nila, dene sêratan sasampunipun dipun cêlêp, lajêng dipun kumbah (kêrok) utawi dipun bironi. Ngumbah punika prêlu ngicali malam ingkang tilasipun badhe kêtumpangan soga, tuwin ambironi punika nyêrat prêlu nutup labêting nila. Dados têrangipun, tembokan punika badhe andadosakên pêthak, kêrokan adamêl panggenan soga, tuwin ambironi punika nutupi warni biru, murih botên kêtumpangan soga.',\n",
       " 'Dene bab saening sogan, punika gumantung wontên saening abên-abênan.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_content[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping done scrapped.txt\n"
     ]
    }
   ],
   "source": [
    "output_file = \"scrapped.txt\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    for item in clean_content:\n",
    "        file.write(item + \"\\n\")\n",
    "        \n",
    "    file.close()\n",
    "\n",
    "print(f\"Scraping done {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utf 8\n",
    "import re\n",
    "\n",
    "standardize_map = {\n",
    "    'ê': 'e', 'è': 'e', 'é': 'e', 'ë': 'e', 'Ê' : 'E',\n",
    "    'à': 'a', 'á': 'a', 'â': 'a', 'ä' : 'a', 'ă' :'a',\n",
    "    'î': 'i', 'ì': 'i', 'í': 'i', 'ï': 'i',\n",
    "    'ô': 'o', 'ò': 'o', 'ó': 'o', 'ö': 'o',\n",
    "    'ù': 'u', 'ú': 'u', 'û': 'u', 'ü': 'u'\n",
    "}\n",
    "\n",
    "def standardize_text(text):\n",
    "    for diacritic_char, standard_char in standardize_map.items():\n",
    "        text = text.replace(diacritic_char, standard_char)\n",
    "    return text\n",
    "\n",
    "with open('scrapped.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "\n",
    "standardized_text = standardize_text(text).lower()\n",
    "\n",
    "with open('standardized.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(standardized_text)\n",
    "    file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punc\n",
    "import re\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "\n",
    "    pattern = f\"[{re.escape(string.punctuation)}]\"\n",
    "    text_no_punctuation = re.sub(pattern, \"\", text)\n",
    "    \n",
    "    return text_no_punctuation\n",
    "\n",
    "v2_standardized_text = remove_punctuation(standardized_text)\n",
    "\n",
    "with open('standardized-2.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(v2_standardized_text)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty lines\n",
    "def remove_empty_lines(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    \n",
    "    non_empty_lines = [line for line in lines if line.strip()]\n",
    "    \n",
    "    cleaned_text = \"\\n\".join(non_empty_lines)\n",
    "    \n",
    "    return cleaned_text    \n",
    "\n",
    "\n",
    "v3_standardized_text = remove_empty_lines(v2_standardized_text)\n",
    "\n",
    "with open('standardized-3.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(v3_standardized_text)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total : 9365\n"
     ]
    }
   ],
   "source": [
    "# count\n",
    "def count_words(text):\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "word_count = count_words(v2_standardized_text)\n",
    "\n",
    "print(\"total :\", word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Kata Unik: 2885\n"
     ]
    }
   ],
   "source": [
    "# unique\n",
    "def get_unique_words(text):\n",
    "    words = text.split()\n",
    "    \n",
    "    unique_words = set(word.lower() for word in words)\n",
    "    \n",
    "    return list(unique_words)\n",
    "\n",
    "unique_words = get_unique_words(v3_standardized_text)\n",
    "length_of_unique_words = len(unique_words)\n",
    "\n",
    "print(\"Jumlah Kata Unik:\", len(unique_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['lingkup', 'pencarian', 'teks', 'dan', 'catatankakinya', 'teks', 'pencarian', '224', 'karakter', 'filter', 'pencarian', 'huruf', 'besarkecil', 'diakritik', 'serta', 'pungtuasi', 'diabaikan', 'karakter', 'dapat', 'digunakan', 'sebagai', 'pengganti', 'zero', 'atau', 'satu', 'huruf', 'sembarang', 'simbol', 'wildcard', 'dapat', 'digunakan', 'sebagai', 'pengganti', 'zero', 'atau', 'sejumlah', 'karakter', 'termasuk', 'spasi', 'mengakomodasi', 'variasi', 'ejaan', 'antara', 'lain', 'dj', 'j', 'tj', 'c', 'j', 'y', 'oe', 'u', 'd', 'dh', 't', 'th'], ['anggitanipun', 'dawud', 'magang', 'guru', 'ing', 'masaran'], ['kacariyos', 'ing', 'jaman', 'kina', 'wonten', 'satunggiling', 'warandha', 'sampun', 'sepuh', 'anama', 'bok', 'randha', 'sambega', 'gegriya', 'wonten', 'ing', 'padhekahan', 'alit', 'anama', 'padhekahan', 'sidhangmiring', 'bawah', 'ing', 'sukawati'], ['bok', 'randha', 'sambega', 'gadhah', 'anak', 'estri', 'satunggil', 'nama', 'pun', 'suwidak', 'loro', 'mila', 'nama', 'makaten', 'awit', 'rambutipun', 'namung', 'wonten', 'suwidak', 'eler', 'untunipun', 'namung', 'kalih', 'iji', 'tur', 'warninipun', 'boten', 'memper', 'tiyang', 'kathah', 'bebasan', 'kados', 'gendruwo', 'thethekan', 'sirahipun', 'pating', 'brenjul', 'bathukipun', 'anonong', 'mripat', 'malethus', 'irung', 'tesek', 'rai', 'mungkal', 'gerang', 'lambe', 'nyoro', 'gulu', 'lekek', 'pundhak', 'barojol', 'tangan', 'ceko', 'bokong', 'tepos', 'suku', 'penthong', 'lampahipun', 'impur'], ['ingkang', 'katedha', 'ing', 'sadintenipun', 'ugi', 'sanes', 'kalihan', 'tiyang', 'kathah', 'kados', 'ta', 'cabuk', 'gereh', 'pethek', 'gorengan', 'botor', 'tuwin', 'cengkaruk', 'gimbal', 'dados', 'meh', 'kados', 'pirantosipun', 'tiyang', 'methil', 'anylameti', 'pantun', 'pantu']]\n"
     ]
    }
   ],
   "source": [
    "# [[],[]]\n",
    "def text_to_2d_list(text):\n",
    "\n",
    "    lines = text.split(\"\\n\")\n",
    "    \n",
    "    words_2d_list = [line.split() for line in lines if line.strip()]\n",
    "    \n",
    "    return words_2d_list\n",
    "\n",
    "\n",
    "words_2d_list = text_to_2d_list(v3_standardized_text)\n",
    "\n",
    "print(words_2d_list[:5])\n",
    "# v3_standardized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_indices(unique_words):\n",
    "    word_to_idx = {}\n",
    "    idx_to_word = {}\n",
    "    for i, word in enumerate(unique_words):\n",
    "        word_to_idx[word] = i\n",
    "        idx_to_word[i] = word\n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "word_to_idx, idx_to_word = build_indices(unique_words)\n",
    "\n",
    "# word_to_idx: Memetakan kata ke indeks.\n",
    "# idx_to_word: Memetakan indeks ke kata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adigang: 0\n",
      "kalebu: 1\n",
      "malongo: 2\n",
      "pados: 3\n",
      "ntenpinten: 4\n",
      "tetiga: 5\n",
      "keceran: 6\n",
      "kadhawuhan: 7\n",
      "andadosaken: 8\n",
      "ngarani: 9\n"
     ]
    }
   ],
   "source": [
    "# word_to_idx\n",
    "for i, (word, idx) in enumerate(word_to_idx.items()):\n",
    "    print(f\"{word}: {idx}\")\n",
    "    if i == 9:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(corpus, word_to_idx):\n",
    "    sequences = []\n",
    "    \n",
    "    for line in corpus:\n",
    "        tokens = line\n",
    "        missing_tokens = [token for token in tokens if token not in word_to_idx]\n",
    "        \n",
    "        for token in missing_tokens:\n",
    "            word_to_idx[token] = len(word_to_idx)  \n",
    "            print(f\"Token '{token}' ditambahkan ke word_to_idx.\")\n",
    "        \n",
    "        for i in range(1, len(tokens)):\n",
    "            i_gram_sequence = tokens[:i+1]\n",
    "            i_gram_sequence_ids = [\n",
    "                word_to_idx[token] for token in i_gram_sequence\n",
    "            ]\n",
    "            sequences.append(i_gram_sequence_ids)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "sequences = prepare_corpus(words_2d_list, word_to_idx)\n",
    "max_sequence_len = max([len(x) for x in sequences])\n",
    "\n",
    "# Membuat urutan token (n-gram).\n",
    "# Menambahkan kata baru ke word_to_idx jika belum ada.\n",
    "# Menghasilkan daftar urutan numerik yang siap digunakan oleh model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1972, 879]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lebokake\n",
      "wekasan\n",
      "berbudi\n"
     ]
    }
   ],
   "source": [
    "print(idx_to_word[1647])\n",
    "print(idx_to_word[867])\n",
    "print(idx_to_word[1452])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9210"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 11:02:29.979275: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-05 11:02:30.110162: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-05 11:02:30.230480: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733371350.335565  373066 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733371350.367388  373066 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 11:02:30.608833: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0, 1972],\n",
       "       [   0,    0,    0, ...,    0, 1972,  879],\n",
       "       [   0,    0,    0, ..., 1972,  879,  480],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1135, 2103, 1058],\n",
       "       [   0,    0,    0, ..., 2103, 1058,  825],\n",
       "       [   0,    0,    0, ..., 1058,  825, 2595]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, Dropout, Embedding, BatchNormalization, Bidirectional\n",
    "from keras.models import Sequential\n",
    "\n",
    "def create_model(max_sequence_len, length_of_unique_words):\n",
    "    model = Sequential([\n",
    "        Embedding(length_of_unique_words, 64, input_length= max_sequence_len-1),\n",
    "        Bidirectional(LSTM(64,return_sequences=True)),\n",
    "        Bidirectional(LSTM(64)),\n",
    "        BatchNormalization(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(length_of_unique_words, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'] \n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghulammuzz/bored-code/nlp/.venv/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1733371414.798208  373066 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model(max_sequence_len, length_of_unique_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9210"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 11:04:33.858285: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 106283400 exceeds 10% of free system memory.\n",
      "2024-12-05 11:04:41.515116: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 38010880 exceeds 10% of free system memory.\n",
      "2024-12-05 11:04:41.527986: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 38010880 exceeds 10% of free system memory.\n",
      "2024-12-05 11:04:41.538020: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 38010880 exceeds 10% of free system memory.\n",
      "2024-12-05 11:04:42.013312: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 38010880 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 959ms/step - accuracy: 0.0048 - loss: 7.9039\n",
      "Epoch 2/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 779ms/step - accuracy: 0.0275 - loss: 7.0669\n",
      "Epoch 3/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 792ms/step - accuracy: 0.0357 - loss: 6.7405\n",
      "Epoch 4/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 760ms/step - accuracy: 0.0317 - loss: 6.6345\n",
      "Epoch 5/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 795ms/step - accuracy: 0.0342 - loss: 6.5229\n",
      "Epoch 6/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 783ms/step - accuracy: 0.0356 - loss: 6.4393\n",
      "Epoch 7/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 735ms/step - accuracy: 0.0336 - loss: 6.3145\n",
      "Epoch 8/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 734ms/step - accuracy: 0.0366 - loss: 6.2035\n",
      "Epoch 9/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 726ms/step - accuracy: 0.0373 - loss: 6.0237\n",
      "Epoch 10/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 756ms/step - accuracy: 0.0413 - loss: 5.8551\n",
      "Epoch 11/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 803ms/step - accuracy: 0.0519 - loss: 5.6924\n",
      "Epoch 12/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 823ms/step - accuracy: 0.0568 - loss: 5.5097\n",
      "Epoch 13/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 829ms/step - accuracy: 0.0675 - loss: 5.3357\n",
      "Epoch 14/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 959ms/step - accuracy: 0.0810 - loss: 5.1183\n",
      "Epoch 15/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.0889 - loss: 4.9156\n",
      "Epoch 16/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.1100 - loss: 4.6440\n",
      "Epoch 17/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 775ms/step - accuracy: 0.1255 - loss: 4.4071\n",
      "Epoch 18/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 764ms/step - accuracy: 0.1567 - loss: 4.1644\n",
      "Epoch 19/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 747ms/step - accuracy: 0.1897 - loss: 3.9028\n",
      "Epoch 20/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 838ms/step - accuracy: 0.2247 - loss: 3.6484\n",
      "Epoch 21/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 780ms/step - accuracy: 0.2691 - loss: 3.3760\n",
      "Epoch 22/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 739ms/step - accuracy: 0.3200 - loss: 3.0989\n",
      "Epoch 23/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 709ms/step - accuracy: 0.3581 - loss: 2.9183\n",
      "Epoch 24/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 714ms/step - accuracy: 0.3994 - loss: 2.6919\n",
      "Epoch 25/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 717ms/step - accuracy: 0.4501 - loss: 2.4594\n",
      "Epoch 26/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 720ms/step - accuracy: 0.4958 - loss: 2.2751\n",
      "Epoch 27/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 784ms/step - accuracy: 0.5260 - loss: 2.0509\n",
      "Epoch 28/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 844ms/step - accuracy: 0.5552 - loss: 1.9318\n",
      "Epoch 29/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 779ms/step - accuracy: 0.5942 - loss: 1.7690\n",
      "Epoch 30/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 741ms/step - accuracy: 0.6207 - loss: 1.6435\n",
      "Epoch 31/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 715ms/step - accuracy: 0.6577 - loss: 1.4932\n",
      "Epoch 32/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 780ms/step - accuracy: 0.6782 - loss: 1.3754\n",
      "Epoch 33/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 805ms/step - accuracy: 0.7032 - loss: 1.2923\n",
      "Epoch 34/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 752ms/step - accuracy: 0.7326 - loss: 1.1617\n",
      "Epoch 35/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 736ms/step - accuracy: 0.7480 - loss: 1.0910\n",
      "Epoch 36/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 740ms/step - accuracy: 0.7781 - loss: 0.9858\n",
      "Epoch 37/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 737ms/step - accuracy: 0.8002 - loss: 0.8938\n",
      "Epoch 38/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 748ms/step - accuracy: 0.8203 - loss: 0.8296\n",
      "Epoch 39/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 773ms/step - accuracy: 0.8380 - loss: 0.7723\n",
      "Epoch 40/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 735ms/step - accuracy: 0.8418 - loss: 0.7126\n",
      "Epoch 41/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 736ms/step - accuracy: 0.8499 - loss: 0.6817\n",
      "Epoch 42/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 748ms/step - accuracy: 0.8692 - loss: 0.6017\n",
      "Epoch 43/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 772ms/step - accuracy: 0.8829 - loss: 0.5710\n",
      "Epoch 44/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 737ms/step - accuracy: 0.8917 - loss: 0.5157\n",
      "Epoch 45/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 734ms/step - accuracy: 0.9077 - loss: 0.4577\n",
      "Epoch 46/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 817ms/step - accuracy: 0.9175 - loss: 0.4298\n",
      "Epoch 47/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 771ms/step - accuracy: 0.9254 - loss: 0.3942\n",
      "Epoch 48/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 735ms/step - accuracy: 0.9349 - loss: 0.3528\n",
      "Epoch 49/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 736ms/step - accuracy: 0.9408 - loss: 0.3236\n",
      "Epoch 50/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 734ms/step - accuracy: 0.9420 - loss: 0.3121\n",
      "Epoch 51/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 732ms/step - accuracy: 0.9495 - loss: 0.2786\n",
      "Epoch 52/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 807ms/step - accuracy: 0.9542 - loss: 0.2661\n",
      "Epoch 53/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 736ms/step - accuracy: 0.9616 - loss: 0.2361\n",
      "Epoch 54/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 733ms/step - accuracy: 0.9610 - loss: 0.2268\n",
      "Epoch 55/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 736ms/step - accuracy: 0.9716 - loss: 0.1880\n",
      "Epoch 56/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 743ms/step - accuracy: 0.9701 - loss: 0.1861\n",
      "Epoch 57/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 823ms/step - accuracy: 0.9720 - loss: 0.1684\n",
      "Epoch 58/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 777ms/step - accuracy: 0.9802 - loss: 0.1481\n",
      "Epoch 59/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 825ms/step - accuracy: 0.9786 - loss: 0.1424\n",
      "Epoch 60/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 785ms/step - accuracy: 0.9846 - loss: 0.1207\n",
      "Epoch 61/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 878ms/step - accuracy: 0.9729 - loss: 0.1837\n",
      "Epoch 62/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 759ms/step - accuracy: 0.6068 - loss: 1.7191\n",
      "Epoch 63/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 778ms/step - accuracy: 0.7597 - loss: 0.8201\n",
      "Epoch 64/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 715ms/step - accuracy: 0.8867 - loss: 0.4312\n",
      "Epoch 65/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 712ms/step - accuracy: 0.9523 - loss: 0.2499\n",
      "Epoch 66/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 754ms/step - accuracy: 0.9745 - loss: 0.1839\n",
      "Epoch 67/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 745ms/step - accuracy: 0.9835 - loss: 0.1398\n",
      "Epoch 68/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 746ms/step - accuracy: 0.9854 - loss: 0.1213\n",
      "Epoch 69/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 745ms/step - accuracy: 0.9884 - loss: 0.1065\n",
      "Epoch 70/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 748ms/step - accuracy: 0.9881 - loss: 0.0908\n",
      "Epoch 71/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 864ms/step - accuracy: 0.9904 - loss: 0.0852\n",
      "Epoch 72/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 822ms/step - accuracy: 0.9908 - loss: 0.0766\n",
      "Epoch 73/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 761ms/step - accuracy: 0.9903 - loss: 0.0731\n",
      "Epoch 74/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 729ms/step - accuracy: 0.9919 - loss: 0.0675\n",
      "Epoch 75/75\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 744ms/step - accuracy: 0.9934 - loss: 0.0640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fd26013ae50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size = 512, epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_text(seed_text, next_words, model, max_seq_len):\n",
    "#     for _ in range(next_words):\n",
    "#         sequences= prepare_corpus(words_2d_list[2], word_to_idx)\n",
    "#         sequences = pad_sequences([sequences[-1]], maxlen=max_seq_len-1, padding='pre')\n",
    "#         predicted = model.predict_classes(sequences, verbose=0)\n",
    "#         output_word = ''\n",
    "#         output_word = idx_to_word[predicted[0]]            \n",
    "#         seed_text = seed_text + \" \" + output_word\n",
    "        \n",
    "#     return seed_text.title()\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_seq_len, word_to_idx, idx_to_word):\n",
    "    for _ in range(next_words):\n",
    "        tokens = seed_text.split()\n",
    "        token_sequence = [word_to_idx.get(token, 0) for token in tokens] \n",
    "        \n",
    "        padded_sequence = pad_sequences([token_sequence], maxlen=max_seq_len - 1, padding='pre')\n",
    "        \n",
    "        predicted_index = np.argmax(model.predict(padded_sequence, verbose=0))\n",
    "        predicted_word = idx_to_word[predicted_index]\n",
    "        \n",
    "        seed_text += f\" {predicted_word}\"\n",
    "    \n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ing wanci dalu panuju sang nata sare suwidak loro amanggihi embokipun abusana sarwa awon nunten anyariyosi embokipun anyariyosaken lelampahanipun nalika kabekta dhateng ing nagari embokipun saklangkung ngungun ing manah mireng wicantening anakipun wangsulanipun\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"ing wanci dalu\", 30, model, max_sequence_len, word_to_idx, idx_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_structure = model.to_json()\n",
    "with open(\"v1_text_generation.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "model.save_weights(\"v1_text_generation.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
